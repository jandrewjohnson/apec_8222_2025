{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06584c0f",
   "metadata": {},
   "source": [
    "# Perceptrons to identify digits\n",
    "\n",
    "Here we will use our perceptron to tell apart digits.\n",
    "\n",
    "## Build the Perceptron Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572590c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time # To see training time\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    A simple Perceptron classifier.\n",
    "    (Slightly modified for OvR usage - predict method will be less relevant,\n",
    "     we'll use _net_input directly for OvR scoring)\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.1, n_iters=100, random_state=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        if random_state:\n",
    "            np.random.seed(random_state)\n",
    "        self.weights_ = None\n",
    "        self.bias_ = None\n",
    "        self.errors_ = []\n",
    "\n",
    "    def _activation_function(self, x):\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "\n",
    "    def _net_input(self, X):\n",
    "        # Ensure X is 2D for np.dot if it's a single sample\n",
    "        X_proc = np.atleast_2d(X)\n",
    "        return np.dot(X_proc, self.weights_) + self.bias_\n",
    "\n",
    "    def fit(self, X, y, verbose=False):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights_ = np.zeros(n_features) # Initialize weights to zeros\n",
    "        # self.weights_ = np.random.rand(n_features) * 0.01 # Or small randoms\n",
    "        self.bias_ = 0.0\n",
    "        self.errors_ = []\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  Initial weights: {self.weights_[:3]}... (len {len(self.weights_)}), Initial bias: {self.bias_}\")\n",
    "\n",
    "        for epoch in range(self.n_iters):\n",
    "            errors_in_epoch = 0\n",
    "            for i in range(n_samples):\n",
    "                xi = X[i]\n",
    "                target = y[i]\n",
    "                \n",
    "                # Predict using current weights\n",
    "                # For direct use, we want the output of activation\n",
    "                prediction_activated = self._activation_function(self._net_input(xi))\n",
    "\n",
    "                update = self.learning_rate * (target - prediction_activated)\n",
    "\n",
    "                if update != 0: # Misclassification\n",
    "                    self.weights_ += update * xi\n",
    "                    self.bias_ += update\n",
    "                    errors_in_epoch += 1\n",
    "            \n",
    "            self.errors_.append(errors_in_epoch)\n",
    "            if verbose and (epoch < 3 or epoch % (self.n_iters // 10 or 1) == 0 or errors_in_epoch == 0):\n",
    "                 print(f\"    Epoch {epoch+1}/{self.n_iters} - Updates: {errors_in_epoch}, Bias: {self.bias_:.4f}\")\n",
    "            \n",
    "            if errors_in_epoch == 0 and epoch > 0: # Converged if no errors (and not first epoch)\n",
    "                if verbose:\n",
    "                    print(f\"    Converged at epoch {epoch+1}!\")\n",
    "                break\n",
    "        if verbose:\n",
    "            print(f\"  Final bias: {self.bias_:.4f}\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step.\"\"\"\n",
    "        return self._activation_function(self._net_input(X)).flatten() # ensure 1D output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6871b3f5",
   "metadata": {},
   "source": [
    "## Build some data (if you look closely, you'll see the digits!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b709494",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Define 5x5 Pixel Representations of Digits ---\n",
    "# 1 for pixel ON, 0 for pixel OFF\n",
    "DIGIT_PATTERNS = {\n",
    "    0: np.array([\n",
    "        [1, 1, 1, 1, 1],\n",
    "        [1, 0, 0, 0, 1],\n",
    "        [1, 0, 0, 0, 1],\n",
    "        [1, 0, 0, 0, 1],\n",
    "        [1, 1, 1, 1, 1]\n",
    "    ]),\n",
    "    1: np.array([\n",
    "        [0, 0, 1, 0, 0],\n",
    "        [0, 1, 1, 0, 0],\n",
    "        [0, 0, 1, 0, 0],\n",
    "        [0, 0, 1, 0, 0],\n",
    "        [0, 1, 1, 1, 0]\n",
    "    ]),\n",
    "    2: np.array([\n",
    "        [1, 1, 1, 1, 0],\n",
    "        [0, 0, 0, 0, 1],\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [1, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 1, 1]\n",
    "    ]),\n",
    "    3: np.array([\n",
    "        [1, 1, 1, 1, 0],\n",
    "        [0, 0, 0, 0, 1],\n",
    "        [0, 1, 1, 1, 1],\n",
    "        [0, 0, 0, 0, 1],\n",
    "        [1, 1, 1, 1, 0]\n",
    "    ]),\n",
    "    4: np.array([\n",
    "        [1, 0, 0, 0, 1],\n",
    "        [1, 0, 0, 0, 1],\n",
    "        [1, 1, 1, 1, 1],\n",
    "        [0, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 1]\n",
    "    ]),\n",
    "    5: np.array([\n",
    "        [1, 1, 1, 1, 1],\n",
    "        [1, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 1, 0],\n",
    "        [0, 0, 0, 0, 1],\n",
    "        [1, 1, 1, 1, 0]\n",
    "    ]),\n",
    "    6: np.array([\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [1, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 1, 0],\n",
    "        [1, 0, 0, 0, 1],\n",
    "        [0, 1, 1, 1, 0]\n",
    "    ]),\n",
    "    7: np.array([\n",
    "        [1, 1, 1, 1, 1],\n",
    "        [0, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 1, 0],\n",
    "        [0, 0, 1, 0, 0],\n",
    "        [0, 0, 1, 0, 0]\n",
    "    ]),\n",
    "    8: np.array([\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [1, 0, 0, 0, 1],\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [1, 0, 0, 0, 1],\n",
    "        [0, 1, 1, 1, 0]\n",
    "    ]),\n",
    "    9: np.array([\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [1, 0, 0, 0, 1],\n",
    "        [0, 1, 1, 1, 1],\n",
    "        [0, 0, 0, 0, 1],\n",
    "        [0, 1, 1, 1, 0]\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3606eb6",
   "metadata": {},
   "source": [
    "## Make a few helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flatten_patterns(patterns_dict):\n",
    "    \"\"\"Flattens 5x5 patterns into 1D vectors and creates labels.\"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for digit, pattern in patterns_dict.items():\n",
    "        X_list.append(pattern.flatten())\n",
    "        y_list.append(digit)\n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "def add_noise(X_original, y_original, num_noisy_versions=5, noise_level=0.05):\n",
    "    \"\"\"Creates noisy versions of the original patterns.\"\"\"\n",
    "    X_noisy_list = []\n",
    "    y_noisy_list = []\n",
    "    \n",
    "    n_features = X_original.shape[1]\n",
    "    \n",
    "    for i in range(X_original.shape[0]):\n",
    "        original_sample = X_original[i]\n",
    "        original_label = y_original[i]\n",
    "        \n",
    "        # Add the original sample\n",
    "        X_noisy_list.append(original_sample)\n",
    "        y_noisy_list.append(original_label)\n",
    "        \n",
    "        for _ in range(num_noisy_versions):\n",
    "            noisy_sample = original_sample.copy()\n",
    "            # Flip a small percentage of pixels\n",
    "            num_flips = int(noise_level * n_features)\n",
    "            flip_indices = np.random.choice(n_features, size=num_flips, replace=False)\n",
    "            for idx in flip_indices:\n",
    "                noisy_sample[idx] = 1 - noisy_sample[idx] # Flip 0 to 1, 1 to 0\n",
    "            X_noisy_list.append(noisy_sample)\n",
    "            y_noisy_list.append(original_label)\n",
    "            \n",
    "    return np.array(X_noisy_list), np.array(y_noisy_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"--- Perceptron for 5x5 Digit Recognition (One-vs-Rest) ---\")\n",
    "\n",
    "# 1. Prepare Data\n",
    "X_perfect, y_perfect = flatten_patterns(DIGIT_PATTERNS)\n",
    "print(f\"\\nPerfect patterns created. X_perfect shape: {X_perfect.shape}, y_perfect shape: {y_perfect.shape}\")\n",
    "\n",
    "# Add noisy versions for more robust training\n",
    "# Increase num_noisy_versions for more data, might need more n_iters then\n",
    "X_train, y_train = add_noise(X_perfect, y_perfect, num_noisy_versions=10, noise_level=0.08) \n",
    "print(f\"Training data with noise. X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Shuffle the training data (good practice)\n",
    "permutation = np.random.permutation(len(X_train))\n",
    "X_train = X_train[permutation]\n",
    "y_train = y_train[permutation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Train One Perceptron per Digit (One-vs-Rest)\n",
    "num_classes = len(DIGIT_PATTERNS)\n",
    "perceptrons_ovr = []\n",
    "learning_rate = 0.1\n",
    "n_iters = 50 # Increase if convergence is slow or data is very noisy/complex\n",
    "\n",
    "print(f\"\\n--- Training {num_classes} Perceptrons (One-vs-Rest) ---\")\n",
    "training_start_time = time.time()\n",
    "\n",
    "for i in range(num_classes): # For digit 0, 1, ..., 9\n",
    "    print(f\"Training Perceptron for digit '{i}' vs Rest...\")\n",
    "    \n",
    "    # Create binary labels for the current Perceptron:\n",
    "    # 1 if it's the current digit, 0 otherwise\n",
    "    y_binary_target = np.where(y_train == i, 1, 0)\n",
    "    \n",
    "    perceptron = Perceptron(learning_rate=learning_rate, n_iters=n_iters, random_state=i) # Different random state for variety\n",
    "    # Pass verbose=True to see epoch details for each perceptron, False for less output\n",
    "    perceptron.fit(X_train, y_binary_target, verbose=False) \n",
    "    perceptrons_ovr.append(perceptron)\n",
    "    # print(f\"  Perceptron for digit '{i}' trained. Final bias: {perceptron.bias_:.3f}, Errors in last epoch: {perceptron.errors_[-1] if perceptron.errors_ else 'N/A'}\")\n",
    "\n",
    "training_duration = time.time() - training_start_time\n",
    "print(f\"--- All Perceptrons trained in {training_duration:.2f} seconds ---\")\n",
    "\n",
    "# 3. Test the OvR Classifier\n",
    "# We will test on the original \"perfect\" patterns and some noisy ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9421318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Testing on Perfect Digit Patterns ---\")\n",
    "correct_predictions_perfect = 0\n",
    "for i in range(len(X_perfect)):\n",
    "    true_label = y_perfect[i]\n",
    "    sample_to_predict = X_perfect[i]\n",
    "    \n",
    "    scores = []\n",
    "    for p_idx, p_model in enumerate(perceptrons_ovr):\n",
    "        # Use the raw net input as the score\n",
    "        # Add np.atleast_2d because _net_input expects 2D X\n",
    "        score = p_model._net_input(np.atleast_2d(sample_to_predict))[0] # Get scalar score\n",
    "        scores.append(score)\n",
    "    \n",
    "    predicted_label = np.argmax(scores)\n",
    "    \n",
    "    print(f\"Digit: {true_label}, Scores: [{', '.join(f'{s:.2f}' for s in scores)}], Predicted: {predicted_label} {'(Correct)' if predicted_label == true_label else '(INCORRECT)'}\")\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions_perfect += 1\n",
    "        \n",
    "accuracy_perfect = (correct_predictions_perfect / len(X_perfect)) * 100\n",
    "print(f\"\\nAccuracy on perfect patterns: {accuracy_perfect:.2f}% ({correct_predictions_perfect}/{len(X_perfect)})\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Testing on a few new Noisy Samples (generated on the fly) ---\")\n",
    "num_test_noisy = 10\n",
    "X_test_noisy, y_test_noisy = add_noise(X_perfect, y_perfect, num_noisy_versions=0, noise_level=0.12) # just one version per original, but noisy\n",
    "# Shuffle test noisy\n",
    "perm_noisy = np.random.permutation(len(X_test_noisy))\n",
    "X_test_noisy = X_test_noisy[perm_noisy][:num_test_noisy]\n",
    "y_test_noisy = y_test_noisy[perm_noisy][:num_test_noisy]\n",
    "\n",
    "\n",
    "correct_predictions_noisy = 0\n",
    "for i in range(len(X_test_noisy)):\n",
    "    true_label = y_test_noisy[i]\n",
    "    sample_to_predict = X_test_noisy[i]\n",
    "    \n",
    "    scores = []\n",
    "    for p_idx, p_model in enumerate(perceptrons_ovr):\n",
    "        score = p_model._net_input(np.atleast_2d(sample_to_predict))[0]\n",
    "        scores.append(score)\n",
    "    \n",
    "    predicted_label = np.argmax(scores)\n",
    "    \n",
    "    # Optionally visualize the noisy input\n",
    "    # print(f\"\\nInput (True: {true_label}):\")\n",
    "    # for row_idx in range(5):\n",
    "    #     print(\" \".join(['#' if x == 1 else '.' for x in sample_to_predict[row_idx*5:(row_idx+1)*5]]))\n",
    "\n",
    "    print(f\"Noisy Digit (True: {true_label}), Scores: [{', '.join(f'{s:.2f}' for s in scores)}], Predicted: {predicted_label} {'(Correct)' if predicted_label == true_label else '(INCORRECT)'}\")\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions_noisy += 1\n",
    "\n",
    "if len(X_test_noisy) > 0:\n",
    "    accuracy_noisy = (correct_predictions_noisy / len(X_test_noisy)) * 100\n",
    "    print(f\"\\nAccuracy on {len(X_test_noisy)} new noisy patterns: {accuracy_noisy:.2f}% ({correct_predictions_noisy}/{len(X_test_noisy)})\")\n",
    "else:\n",
    "    print(\"\\nNo new noisy patterns generated for testing.\")\n",
    "\n",
    "print(\"\\nNote: The 'scores' are the raw net_input (w.x + b) from each Perceptron.\")\n",
    "print(\"The digit corresponding to the Perceptron with the highest score is chosen.\")\n",
    "print(\"If patterns are too similar or noise is too high, misclassifications can occur.\")\n",
    "print(\"Try adjusting `n_iters`, `learning_rate`, `num_noisy_versions`, and `noise_level`.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env8222a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
